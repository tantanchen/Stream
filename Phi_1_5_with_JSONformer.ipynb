{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tantanchen/Stream/blob/main/Phi_1_5_with_JSONformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install einops\n",
        "!pip install jsonformer"
      ],
      "metadata": {
        "id": "BLsaLpLP6QSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "from jsonformer import Jsonformer"
      ],
      "metadata": {
        "id": "fLjPZ5ke6q8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"Open-Orca/oo-phi-1_5\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16\n",
        "    ).to('cuda')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Open-Orca/oo-phi-1_5\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMeitcMd7G-a",
        "outputId": "8ae36126-9942-4551-9e50-eb48f60e2b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"I am a data generator, I will generate unique and uncommon contact info consisting of names and address\"\n",
        "input = \"Generate some unique name and addresses\"\n",
        "\n",
        "prefix = \"<|im_start|>\"\n",
        "suffix = \"<|im_end|>\\n\"\n",
        "sys_format = prefix + \"system\\n\" + sys_prompt + suffix\n",
        "user_format = prefix + \"user\\n\" + input + suffix\n",
        "assistant_format = prefix + \"assistant\\n\"\n",
        "input_text = sys_format + user_format + assistant_format"
      ],
      "metadata": {
        "id": "1xSzfA8nxGfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_length=1024, temperature=0.9, top_p=0.95, repetition_penalty=1.1,\n",
        "    do_sample=True, use_cache=True,\n",
        "    eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", return_attention_mask=False).to('cuda')\n",
        "outputs = model.generate(**inputs, generation_config=generation_config)\n",
        "\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SGgTfikxC-z",
        "outputId": "800ea332-656b-4699-8608-b132e8988c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "I am a data generator, I will generate unique and uncommon contact info consisting of names and address<|im_end|>\n",
            "<|im_start|>user\n",
            "Generate some unique name and addresses<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Here are 10 unique names and addresses:\n",
            "\n",
            "1. John Smith, 123 Main Street, New York City, NY 10001\n",
            "2. Jane Doe, 456 Oak Avenue, Los Angeles, CA 90055\n",
            "3. Bob Johnson, 789 Pine Road, Seattle, WA 98104\n",
            "4. Mary Thompson, 321 Harbor Drive, London, UK 50207\n",
            "5. Alex Lee, 567 Elm Boulevard, Sydney, Australia 57601\n",
            "6. Sarah Kim, 890 Cedar Avenue, Tokyo, Japan Tōku 05001\n",
            "7. Michael Lee, 987 Maple Street, San Francisco, CA 94117\n",
            "8. Olivia Davis, 345 Birchwood Drive, Seoul, Kő, Republic of Korea 90242\n",
            "9. David Brown, 678 Maple Lane, Paris, France 678431\n",
            "10. Lisa Wilson, 908 Fifth Avenue, London, UK 75111\n",
            "\n",
            "Please note that the street numbers might be slightly different as they are for locations in Europe or other regions not included in the list above. However, all these names have unique addresses to help differentiate between various individuals.<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bos_token = tokenizer.bos_token\n",
        "eos_token = tokenizer.eos_token\n",
        "\n",
        "print(bos_token)\n",
        "print(eos_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsmkWqjTfYX5",
        "outputId": "acafd7de-84d6-4367-f73f-a85b65850a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>\n",
            "<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"first_name\": {\"type\": \"string\"},\n",
        "        \"middle_name\": {\"type\": \"string\"},\n",
        "        \"last_name\": {\"type\": \"string\"},\n",
        "        \"street\": {\"type\": \"string\"},\n",
        "        \"city\": {\"type\": \"string\"},\n",
        "        \"state\": {\"type\": \"string\"},\n",
        "        \"postal_code\": {\"type\": \"string\"}\n",
        "\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "prompt = \"Matthew L Keller and Julie Smith 983 Second Ave, Springfield, New York, 19283\"\n",
        "jsonformer = Jsonformer(model, tokenizer, json_schema, text)\n",
        "generated_data = jsonformer()\n",
        "\n",
        "print(json.dumps(generated_data, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4lqHzV3qkq-",
        "outputId": "095d6010-0e27-43d9-c1c3-6fcdd22356e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"first_name\": \"John\",\n",
            "    \"middle_name\": \"Smith\",\n",
            "    \"last_name\": \"Smith\",\n",
            "    \"street\": \"123 Main Street\",\n",
            "    \"city\": \"New York City\",\n",
            "    \"state\": \"NY\",\n",
            "    \"postal_code\": \"10001\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43oDMATqtgIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}